{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Downloading raw read data from SRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will download the raw Illumina data associated with the study and rename the files as specified in the text file `SraAccList.txt` provided in the `data` directory.\n",
    "\n",
    "The cell expects modules of the [SRA Toolkit](http://www.ncbi.nlm.nih.gov/Traces/sra/?view=toolkit_doc) (`prefetch` and `fastq-dump`) to be in your path (tested with SRA Toolkit version 2.3.5). `prefetch` downloads data in sra format and places it per default into `~/ncbi/public/sra/`. `fastq-dump` converts the sra formatted data to gzipped fastq."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__removed again as I've not set it up correctly__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Processing read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure complete reproducibility all subsequent processing of the read data was performed in a docker container which we have made available [here](https://hub.docker.com/r/chrishah/metabeat/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will print out the help file for metaBEAT_global.py allowing readers to follow the commands used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "metaBEAT_global.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PERFORM A CLUSTERING ANALYSIS TO CHECK FOR OPTIMAL CLUSTER READ DEPTH__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will ultimately be clustering and filtering our data to unique sequences but we don't know what read depth we should accept as a minimum valid cluster size. To investigate this we will iterate across different minimum read depths and examine the effect this has on clusters retained for taxonomic assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with coverage 1\n",
      "running with coverage 6\n",
      "running with coverage 11\n",
      "running with coverage 16\n",
      "running with coverage 21\n",
      "running with coverage 26\n",
      "running with coverage 31\n",
      "running with coverage 36\n",
      "running with coverage 41\n",
      "running with coverage 46\n",
      "running with coverage 51\n",
      "running with coverage 56\n",
      "running with coverage 61\n",
      "running with coverage 66\n",
      "running with coverage 71\n",
      "running with coverage 76\n",
      "running with coverage 81\n",
      "running with coverage 86\n",
      "running with coverage 91\n",
      "running with coverage 96\n",
      "running with coverage 101\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Move to the correct folder\n",
    "mkdir -p ../Processed_data/Cluster_size\n",
    "cd ../Processed_data/Cluster_size\n",
    "\n",
    "# Loop across minimum cluster sizes\n",
    "for i in $(seq 1 5 101)\n",
    "do\n",
    "      echo -e \"running with coverage $i\"\n",
    "      metaBEAT_global.py -Q ../../data/OPM2_QueryMap.txt --cluster --merge --merged_only --length_filter 310 --product_length 400 --clust_match 1.0 --clust_cov $i --trim_minlength 100 -@ James.Kitson@newcastle.ac.uk -o metaBEAT &> cluster_log.txt\n",
    "      mv metaBEAT_read_stats.csv metaBEAT_read_stats_$i.csv\n",
    "done\n",
    "\n",
    "# Combine the files into one large output for plotting in R\n",
    "cat metaBEAT_read_stats_1.csv | head -n 1 > ../../data/combined_read_stats.csv\n",
    "cat metaBEAT_read_stats_* | grep \"sample,\" -v >> ../../data/combined_read_stats.csv\n",
    "cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PERFORMING FINAL ANALYSES (INCL. TAXONOMIC ASSIGNMENT) FROM RAW READ DATA__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell does the trimming and clustering then does a BLAST against a complete local copy of genbank using the metaBEAT pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Move to the correct folder\n",
    "mkdir -p ../Processed_data/Final_analysis\n",
    "cd ../Processed_data/Final_analysis\n",
    "\n",
    "# Perform the clustering and assignment analyses with parameters determined above\n",
    "metaBEAT_global.py -Q ../../data/OPM2_QueryMap.txt --cluster --merge --merged_only \\\n",
    "--length_filter 310 --product_length 400 --clust_match 1.0 --clust_cov 50 --trim_minlength 100 -E \\\n",
    "-n 6 -v --blast --blast_db ../../../../Genbank/nt/nt \\\n",
    "--min_ident 0.95 --min_ali_length 0.90 -@ James.Kitson@newcastle.ac.uk &> OPM2BLAST_log.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MetaBEAT produces files in the .biom format for easy use with QIIME but we will be using the output in R for plotting figures. The next cell strips out all the QIIME .biom formatting and leaves us with a rectangular read table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../Processed_data/Final_analysis/\n",
    "\n",
    "cat ./GLOBAL/BLAST_0.95/metaBEAT-by-taxonomy-readcounts.blast.tsv | \\\n",
    "grep \"# \" -v | sed 's/#//' | sed 's/\\.blast//g' | sed 's/ /_/' | perl -ne \\\n",
    "'chomp; @a=split(\"\\t\"); pop(@a); $out=join(\"\\t\", @a); print \"$out\\n\"' \\\n",
    "> ./GLOBAL/BLAST_0.95/metaBEAT-processed.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reformatted metaBEAT data could be used as is but we'll transpose our table now to make life easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = '../Processed_data/Final_analysis/GLOBAL/BLAST_0.95/metaBEAT-processed.tsv'\n",
    "output_filename = '../data/metaBEAT_transpose.tsv'\n",
    "\n",
    "df = pd.read_table(filename)\n",
    "df = df.transpose()\n",
    "df.to_csv(output_filename, header=None, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

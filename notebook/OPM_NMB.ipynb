{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Downloading raw read data from SRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will download the raw Illumina data associated with the study and rename the files as specified in the text file `SraAccList.txt` provided in the `data` directory.\n",
    "\n",
    "The cell expects modules of the [SRA Toolkit](http://www.ncbi.nlm.nih.gov/Traces/sra/?view=toolkit_doc) (`prefetch` and `fastq-dump`) to be in your path (tested with SRA Toolkit version 2.3.5). `prefetch` downloads data in sra format and places it per default into `~/ncbi/public/sra/`. `fastq-dump` converts the sra formatted data to gzipped fastq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sra_path=\"~/ncbi/public/sra\"\n",
    "\n",
    "cd data\n",
    "\n",
    "for line in $(cat SraAccList.txt)\n",
    "do \n",
    "    name=$(echo -e \"$line\" | cut -d \",\" -f 1)\n",
    "    acc=$(echo -e \"$line\" | cut -d \",\" -f 2)\n",
    "    echo -e \"\\nDOWNLOADING: $name\\t$acc\\n################\\n\"\n",
    "    prefetch $acc\n",
    "    fastq-dump --split-files --gzip --defline-seq '@$ac-$sn/$ri' --defline-qual '+' $sra_path/$acc.sra\n",
    "    mv $acc\\_1.fastq.gz $name\\_1.fastq.gz\n",
    "    mv $acc\\_2.fastq.gz $name\\_2.fastq.gz\n",
    "done\n",
    "\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Processing read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EXPLORING CLUSTERING PARAMETER SPACE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell just performs the clustering steps across a range of clustering parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir cluster_space\n",
    "cd cluster_space\n",
    "\n",
    "for i in $(seq 0.90 0.01 1)\n",
    "do\n",
    "    for j in $(seq 100 50 500)\n",
    "    do\n",
    "        echo -e \"running with clustering threshold $i coverage $j\"\n",
    "        metaBEAT.py -Q ../../data/QUERYmap --merge --merged_only --length_filter 310 --product_length 400 --clust_match $i --clust_cov $j -n 5 -v --cluster &> log_$i-$j.txt\n",
    "        mv reads_stats.csv reads_stats_$i-$j.csv\n",
    "    done\n",
    "done\n",
    "\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we concatenate all results into a single file and format it ready for R processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat cluster_space/reads_stats_0.90-100.csv | head -n 1 > cluster_space/combined_reads_stats.csv\n",
    "cat cluster_space/reads_stats_* | grep \"sample,\" -v >> cluster_space/combined_reads_stats.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `cluster_space/combined_reads_stats.csv` is processed with the R script `clustering_paramters_heat.R` to produce Figure 5 in the manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PERFORMING FINAL ANALYSES (INCL. TAXONOMIC ASSIGNMENT) FROM RAW READ DATA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir final_analysis\n",
    "cd final_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell does the trimming and clustering then does a BLAST assignment based on the custom reference database (`positives.gb`) using the metaBEAT pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!metaBEAT.py -Q ../../data/QUERYmap -R ../../data/REFmap --merge --merged_only --length_filter 310 --product_length 400 --clust_match 0.95 --clust_cov 50 --trim_minlength 100 -n 4 --cluster --PCR_primer ../../data/PCR_primers.fasta -E -b --min_ident 0.95 > log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read summary stats produced by metaBEAT (`reads_stats.csv`) were processed in R with the script `trimming_results_script.R` to produce Figs 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `metaBEAT.tsv` contains the results from the taxonomic assignment in human-readable text format. The pipeline also produces the results in [BIOM](http://biom-format.org/) format (`metaBEAT.biom`). The next cell will re-format the text file for subsequent processing in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat metaBEAT.tsv | grep \"# \" -v | sed 's/#//' | sed 's/\\.blast//g' | sed 's/ /_/' | perl -ne 'chomp; @a=split(\"\\t\"); pop(@a); $out=join(\"\\t\", @a); print \"$out\\n\"' > metaBEAT-processed.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `metaBEAT-processed.tsv` was used to produce Figure 6 with the R script `well_composition_script.R`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
